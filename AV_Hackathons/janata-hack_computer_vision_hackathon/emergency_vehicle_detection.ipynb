{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "location = 'C:\\\\Users\\\\ak19919\\\\Downloads\\\\Github\\\\Analytics-Vidya\\\\janata-hack_computer_vision_hackathon\\\\vehicles'\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = location + '\\\\train_labelled'\n",
    "DIR_TEST = location + '\\\\test_labelled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53590948c17546269acb773abc119083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loop over the image paths in the training set\n",
    "for imagePath in tqdm(os.listdir(DIR_TRAIN)):\n",
    "    # extract the label of the vehicle\n",
    "    label = imagePath.split('-')[0]\n",
    "    path = os.path.join(DIR_TRAIN, imagePath)\n",
    "    # load the image, convert it to grayscale, and detect edges\n",
    "    image = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edged = imutils.auto_canny(gray)\n",
    "\n",
    "    # find contours in the edge map, keeping only the largest one which\n",
    "    # is presmumed to be the car logo\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "\n",
    "    # extract the logo of the car and resize it to a canonical width\n",
    "    # and height\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    logo = gray[y:y + h, x:x + w]\n",
    "    logo = cv2.resize(logo, (224, 224))\n",
    "\n",
    "    # extract Histogram of Oriented Gradients from the logo\n",
    "    H = feature.hog(logo, orientations = 9, pixels_per_cell = (10, 10),\n",
    "        cells_per_block = (2, 2), transform_sqrt = True, block_norm = \"L1\")\n",
    "\n",
    "    # update the data and labels\n",
    "    data.append(H)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training classifier...\n",
      "[INFO] evaluating...\n"
     ]
    }
   ],
   "source": [
    "# \"train\" the nearest neighbors classifier\n",
    "print(\"[INFO] training classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors = 1)\n",
    "model.fit(data, labels)\n",
    "print(\"[INFO] evaluating...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b37e4734a241e3bb21d0b620235833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=329.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for imagePath in tqdm(os.listdir(DIR_TEST)):\n",
    "    # extract the label of the vehicle\n",
    "    i = int(imagePath.split('-')[1].split('.')[0])\n",
    "    path = os.path.join(DIR_TEST, imagePath)\n",
    "    # load the image, convert it to grayscale, and detect edges\n",
    "    image = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    logo = cv2.resize(gray, (224, 224))\n",
    "\n",
    "    # extract Histogram of Oriented Gradients from the test image and\n",
    "    # predict the make of the car\n",
    "    (H, hogImage) = feature.hog(logo, orientations = 9, pixels_per_cell = (10, 10),\n",
    "        cells_per_block = (2, 2), transform_sqrt = True, block_norm = \"L1\", visualize = True)\n",
    "    pred = model.predict(H.reshape(1, -1))[0]\n",
    "\n",
    "    # visualize the HOG image\n",
    "    hogImage = exposure.rescale_intensity(hogImage, out_range = (0, 255))\n",
    "    hogImage = hogImage.astype(\"uint8\")\n",
    "    cv2.imshow(\"HOG Image #{}\".format(i + 1), hogImage)\n",
    "\n",
    "    # draw the prediction on the test image and display it\n",
    "    cv2.putText(image, pred.title(), (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "        (0, 255, 0), 3)\n",
    "    cv2.imshow(\"Test Image #{}\".format(i + 1), image)\n",
    "    cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
